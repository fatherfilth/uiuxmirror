---
phase: 03-synthesis-inference-engine
plan: 03
type: execute
wave: 2
depends_on: ["03-01"]
files_modified:
  - src/synthesis/llm-refiner.ts
  - src/synthesis/prompt-builder.ts
autonomous: true

user_setup:
  - service: anthropic
    why: "Claude API for nuanced design decisions (motion timing, edge states, microcopy)"
    env_vars:
      - name: ANTHROPIC_API_KEY
        source: "Anthropic Console -> Settings -> API Keys (https://console.anthropic.com/settings/keys)"

must_haves:
  truths:
    - "LLM refiner calls Claude API with structured outputs for guaranteed JSON schema compliance"
    - "LLM refiner only uses tokens and patterns from extracted DesignDNA (no hallucination)"
    - "Every LLM decision includes reasoning and evidence citations"
    - "Prompt builder formats DesignDNA as context with cache_control for cost efficiency"
    - "LLM refiner gracefully degrades when API key missing or API unavailable"
  artifacts:
    - path: "src/synthesis/llm-refiner.ts"
      provides: "Claude API integration for nuanced design decisions"
      exports: ["llmRefine", "llmDecideMotionTiming", "llmDecideEdgeStates"]
    - path: "src/synthesis/prompt-builder.ts"
      provides: "Builds system prompts with design DNA context and cache control"
      exports: ["buildSystemPrompt", "buildMotionPrompt", "buildEdgeStatePrompt"]
  key_links:
    - from: "src/synthesis/llm-refiner.ts"
      to: "@anthropic-ai/sdk"
      via: "Claude API client"
      pattern: "import Anthropic"
    - from: "src/synthesis/llm-refiner.ts"
      to: "src/synthesis/prompt-builder.ts"
      via: "builds prompts for API calls"
      pattern: "buildSystemPrompt|buildMotionPrompt"
    - from: "src/synthesis/llm-refiner.ts"
      to: "zod"
      via: "defines response schemas for structured outputs"
      pattern: "import.*zod"
---

<objective>
Implement the LLM refiner that calls Claude API for nuanced design decisions that cannot be determined by rules alone.

Purpose: This is Stage 2 of the two-stage synthesis pipeline. While the rule engine handles deterministic structure and token application, the LLM refiner handles genuinely nuanced decisions: motion timing/easing, loading/error state presentation, microcopy tone, and complex accessibility guidance. Uses structured outputs for guaranteed schema compliance.

Output: LLM refiner module with Claude API integration and prompt builder with caching support.
</objective>

<execution_context>
@C:/Users/Karl/.claude/get-shit-done/workflows/execute-plan.md
@C:/Users/Karl/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/03-synthesis-inference-engine/03-RESEARCH.md
@.planning/phases/03-synthesis-inference-engine/03-01-SUMMARY.md
@src/types/synthesis.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Implement prompt builder with caching</name>
  <files>
    src/synthesis/prompt-builder.ts
  </files>
  <action>
Create `src/synthesis/prompt-builder.ts`:

**`buildSystemPrompt(designDNA: DesignDNA): MessageCreateParams['system']`**
- Formats DesignDNA into a structured system prompt for Claude
- Include:
  - Available color tokens (canonical hex values with occurrence counts)
  - Typography tokens (font family, sizes, weights)
  - Spacing tokens (values with scale information)
  - Observed components with canonical styles and confidence scores
  - Observed motion patterns (transition durations, easings)
- Mark with `cache_control: { type: 'ephemeral' }` for prompt caching (5-min lifetime)
- Keep under 4000 tokens to stay within caching sweet spot
- Return as array of content blocks per Anthropic SDK format

**`buildMotionPrompt(componentType: string, html: string, designDNA: DesignDNA): string`**
- Build user message for motion timing decisions
- Include: observed motion patterns from DesignDNA, component structure, available easing functions
- Instructions: only use durations/easings observed in DNA, provide evidence IDs, rate confidence
- Instruct Claude to return JSON matching MotionTimingSchema

**`buildEdgeStatePrompt(componentType: string, html: string, designDNA: DesignDNA): string`**
- Build user message for loading/error state decisions
- Include: component structure, available tokens, observed loading/error patterns if any
- Instructions: decide loading presentation (spinner/skeleton/text), error styling (color, icon, message placement)
- Instruct Claude to return JSON matching EdgeStateSchema

**`buildMicrocopyPrompt(componentType: string, designDNA: DesignDNA): string`**
- Build user message for microcopy decisions (button text, labels, placeholder text)
- Include: component type, observed text patterns from similar components
- Instructions: match tone/voice of observed content
- Instruct Claude to return JSON matching MicrocopySchema

**Helper: `formatTokensForPrompt(designDNA: DesignDNA): string`**
- Compact token summary: one line per token (name: value, observed on N pages)
- Group by category (colors, typography, spacing, etc.)

**Helper: `formatComponentsForPrompt(designDNA: DesignDNA): string`**
- Compact component summary: type, variant count, confidence, canonical styles
  </action>
  <verify>
    Run `npx tsc --noEmit` — must pass with 0 errors.
  </verify>
  <done>
    Prompt builder creates structured system prompts with cache control and focused user prompts for motion, edge states, and microcopy decisions.
  </done>
</task>

<task type="auto">
  <name>Task 2: Implement LLM refiner with structured outputs</name>
  <files>
    src/synthesis/llm-refiner.ts
    src/synthesis/index.ts
  </files>
  <action>
Create `src/synthesis/llm-refiner.ts`:

**Zod schemas for structured outputs:**

`MotionTimingSchema`:
```typescript
z.object({
  transitions: z.array(z.object({
    property: z.string(),
    duration: z.string(),
    timingFunction: z.string(),
    reasoning: z.string(),
    confidence: z.number().min(0).max(1),
    evidenceIds: z.array(z.string())
  }))
})
```

`EdgeStateSchema`:
```typescript
z.object({
  loadingState: z.object({
    presentation: z.enum(['spinner', 'skeleton', 'text-change', 'progress-bar']),
    styles: z.record(z.string()),
    ariaAttributes: z.record(z.string()),
    reasoning: z.string(),
    confidence: z.number().min(0).max(1)
  }),
  errorState: z.object({
    presentation: z.enum(['inline-message', 'toast', 'banner', 'icon']),
    styles: z.record(z.string()),
    ariaAttributes: z.record(z.string()),
    reasoning: z.string(),
    confidence: z.number().min(0).max(1)
  })
})
```

`MicrocopySchema`:
```typescript
z.object({
  labels: z.record(z.string()),
  placeholders: z.record(z.string()),
  buttonText: z.string().optional(),
  errorMessages: z.record(z.string()).optional(),
  reasoning: z.string(),
  confidence: z.number().min(0).max(1)
})
```

**Core function: `llmRefine(structure: StructuralSynthesis, designDNA: DesignDNA): Promise<LLMRefinement>`**

`LLMRefinement` type (add to synthesis.ts):
```typescript
interface LLMRefinement {
  motionTimings: z.infer<typeof MotionTimingSchema> | null;
  edgeStates: z.infer<typeof EdgeStateSchema> | null;
  microcopy: z.infer<typeof MicrocopySchema> | null;
  decisions: SynthesisDecision[];
  evidence: EvidenceLink[];
}
```

Implementation:
1. Check if ANTHROPIC_API_KEY is set in process.env. If not, return null refinements with a warning log and empty decisions. This makes LLM refinement gracefully optional.
2. Create Anthropic client: `new Anthropic({ apiKey: process.env.ANTHROPIC_API_KEY })`
3. Build system prompt with `buildSystemPrompt(designDNA)` (cached)
4. Call three API endpoints in sequence (not parallel, to respect rate limits):
   a. Motion timing via `buildMotionPrompt()` with MotionTimingSchema
   b. Edge states via `buildEdgeStatePrompt()` with EdgeStateSchema
   c. Microcopy via `buildMicrocopyPrompt()` with MicrocopySchema
5. Each API call uses structured outputs:
   ```typescript
   response_format: {
     type: 'json_schema',
     json_schema: {
       name: 'schema_name',
       schema: zodToJsonSchema(schema),
       strict: true
     }
   }
   ```
   With header: `{ 'anthropic-beta': 'structured-outputs-2025-11-13' }`
6. Use model `'claude-sonnet-4-5-20250514'` for refinement (Sonnet is sufficient for style decisions, cheaper than Opus)
7. Wrap each call in try/catch. If any call fails, log warning and set that refinement to null. Never let API errors crash synthesis.
8. Convert each LLM response to SynthesisDecision[] with sourceType 'llm_decision' and the LLM's reasoning/confidence.

**Note on zod-to-json-schema:** Check if `zod-to-json-schema` is needed. The Anthropic SDK may support zod schemas directly. If not, install `zod-to-json-schema`. Alternatively, manually construct JSON schema objects from the zod definitions to avoid an extra dependency.

Update `src/synthesis/index.ts` to export llm-refiner and prompt-builder functions.
  </action>
  <verify>
    Run `npx tsc --noEmit` — must pass with 0 errors.
    Verify graceful degradation: code must not throw when ANTHROPIC_API_KEY is not set.
  </verify>
  <done>
    LLM refiner calls Claude API with structured outputs for motion, edge states, and microcopy. Gracefully degrades when API unavailable. All decisions include reasoning and evidence.
  </done>
</task>

</tasks>

<verification>
1. `npx tsc --noEmit` passes with 0 errors
2. Prompt builder creates cached system prompts under 4000 tokens
3. LLM refiner uses structured outputs with strict JSON schema
4. Graceful degradation when ANTHROPIC_API_KEY missing (returns null refinements, no crash)
5. All LLM decisions converted to SynthesisDecision[] with evidence
6. Model set to claude-sonnet-4-5-20250514 (cost-appropriate for style decisions)
</verification>

<success_criteria>
- LLM refiner integrates Claude API with structured outputs
- Graceful degradation when API unavailable
- Every LLM decision includes confidence score and reasoning
- Prompt builder formats DNA context with cache control
</success_criteria>

<output>
After completion, create `.planning/phases/03-synthesis-inference-engine/03-03-SUMMARY.md`
</output>
