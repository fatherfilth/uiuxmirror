---
phase: 01-foundation-crawling-infrastructure
plan: 07
type: execute
wave: 5
depends_on: ["01-06"]
files_modified:
  - tests/integration/pipeline.test.ts
  - tests/unit/extractors.test.ts
  - tests/fixtures/sample-page.html
  - vitest.config.ts
autonomous: false

must_haves:
  truths:
    - "End-to-end pipeline crawls a real site and produces tokens with evidence"
    - "All 8 token extractors produce valid typed output"
    - "Re-crawl diff detection works correctly"
    - "User visually confirms output quality against a known site"
  artifacts:
    - path: "tests/integration/pipeline.test.ts"
      provides: "Integration test for full pipeline"
      min_lines: 50
    - path: "tests/unit/extractors.test.ts"
      provides: "Unit tests for individual extractors"
      min_lines: 80
  key_links:
    - from: "tests/integration/pipeline.test.ts"
      to: "src/orchestrator.ts"
      via: "calls runPipeline with test config"
      pattern: "runPipeline"
---

<objective>
Write integration and unit tests for the complete Phase 1 pipeline, then verify end-to-end against a real website with human inspection.

Purpose: Confirm all Phase 1 requirements work together. The pipeline should extract meaningful tokens from a real site. Tests catch regressions. Human verification ensures the output quality matches expectations.

Output: Test suite that validates the pipeline, plus human-verified confirmation that the crawler and extractors produce useful design token output.
</objective>

<execution_context>
@C:/Users/Karl/.claude/get-shit-done/workflows/execute-plan.md
@C:/Users/Karl/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@C:/Users/Karl/UIUX-Mirror/.planning/PROJECT.md
@C:/Users/Karl/UIUX-Mirror/.planning/ROADMAP.md
@C:/Users/Karl/UIUX-Mirror/.planning/phases/01-foundation-crawling-infrastructure/01-06-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Write unit tests for extractors and integration tests for pipeline</name>
  <files>tests/unit/extractors.test.ts, tests/integration/pipeline.test.ts, tests/fixtures/sample-page.html, vitest.config.ts</files>
  <action>
Set up vitest configuration and write tests.

1. vitest.config.ts at project root:
```typescript
import { defineConfig } from 'vitest/config';
export default defineConfig({
  test: {
    include: ['tests/**/*.test.ts'],
    testTimeout: 60000,  // 60s for integration tests with Playwright
  },
});
```

2. tests/fixtures/sample-page.html:
   Create a static HTML file with known design tokens for predictable extraction:
   - A few elements with specific colors (#3b82f6, #ef4444, #10b981)
   - Typography: Inter font family, sizes 14px, 16px, 24px, 32px
   - Spacing: 8px, 16px, 24px padding values
   - CSS custom properties: --primary-color, --text-color, --spacing-md
   - Border radius: 4px, 8px
   - Box shadow on a card element
   - A simple transition: 0.2s ease on buttons
   - An inline SVG icon
   - An img element with aspect ratio

3. tests/unit/extractors.test.ts:
   Test extractors against the fixture page using Playwright directly (not the crawler).

   ```typescript
   import { chromium, Browser, Page } from 'playwright';
   import { describe, it, expect, beforeAll, afterAll } from 'vitest';
   import path from 'path';

   let browser: Browser;
   let page: Page;

   beforeAll(async () => {
     browser = await chromium.launch();
     const context = await browser.newContext();
     page = await context.newPage();
     const fixturePath = path.resolve('tests/fixtures/sample-page.html');
     await page.goto(`file://${fixturePath}`);
   });

   afterAll(async () => { await browser.close(); });
   ```

   Tests:
   a. extractColors returns ColorToken[] with known colors from fixture
   b. extractTypography returns font sizes matching fixture (14, 16, 24, 32px)
   c. extractSpacing returns known spacing values
   d. extractCustomProperties returns --primary-color etc.
   e. extractRadii returns known radii
   f. extractShadows returns shadow from card element
   g. extractMotionTokens returns transition duration from button
   h. extractIconTokens detects inline SVG
   i. extractImageryTokens detects img aspect ratio
   j. All tokens have evidence with selector and computedStyles

4. tests/integration/pipeline.test.ts:
   Integration test using the full pipeline against example.com.

   ```typescript
   import { describe, it, expect } from 'vitest';
   import { runPipeline } from '../../src/index.js';
   import { loadConfig } from '../../src/shared/index.js';
   import fs from 'fs-extra';

   describe('Pipeline Integration', () => {
     const outputDir = '.uidna-test';

     afterAll(async () => { await fs.remove(outputDir); });

     it('crawls example.com and extracts tokens', async () => {
       const config = loadConfig({
         seedUrls: ['https://example.com'],
         maxPages: 1,
         maxDepth: 0,
         outputDir,
       });

       const result = await runPipeline({ config });

       expect(result.crawlResult.pagesProcessed).toBe(1);
       expect(result.crawlResult.pagesFailed).toBe(0);
       expect(result.evidenceCount).toBeGreaterThan(0);
       expect(result.outputDir).toBe(outputDir);

       // Verify files on disk
       expect(await fs.pathExists(path.join(outputDir, 'tokens'))).toBe(true);
       expect(await fs.pathExists(path.join(outputDir, 'evidence'))).toBe(true);
       expect(await fs.pathExists(path.join(outputDir, 'snapshots'))).toBe(true);
     });

     it('second crawl produces diff report', async () => {
       const config = loadConfig({
         seedUrls: ['https://example.com'],
         maxPages: 1,
         maxDepth: 0,
         outputDir,
       });

       const result = await runPipeline({ config });

       expect(result.diffResult).toBeDefined();
       expect(result.diffResult!.unchanged.length).toBeGreaterThanOrEqual(0);
     });
   });
   ```

Run tests with: `npx vitest run`
  </action>
  <verify>
Run `npx vitest run` -- all tests should pass.
Specifically:
- Unit tests confirm extractors produce typed tokens from fixture HTML
- Integration test confirms pipeline produces output files from example.com
- Second pipeline run confirms diff detection works
  </verify>
  <done>Unit tests validate all 8 extractors against fixture HTML with known values. Integration tests validate end-to-end pipeline against example.com. Diff detection confirmed by sequential crawl test.</done>
</task>

<task type="checkpoint:human-verify" gate="blocking">
  <name>Task 2: Human verification of pipeline output quality</name>
  <files>N/A</files>
  <action>
Present the user with instructions to run the pipeline against a real website and inspect the output quality. The automated tests from Task 1 confirm correctness; this checkpoint confirms the output is *useful* and *reasonable* to a human reviewer.

Steps prepared for the user:
1. Run pipeline against a real site (tailwindcss.com or similar)
2. Inspect extracted token files for reasonableness
3. Verify evidence entries have complete provenance
4. Confirm re-crawl diff works
  </action>
  <verify>
User inspects:
1. Run the pipeline against a real website (suggest https://tailwindcss.com or another site you are familiar with):
   ```
   cd C:/Users/Karl/UIUX-Mirror
   npx tsx -e "
   import { runPipeline } from './src/index.js';
   import { loadConfig } from './src/shared/index.js';
   const config = loadConfig({ seedUrls: ['https://tailwindcss.com'], maxPages: 5, maxDepth: 1 });
   const result = await runPipeline({ config, onProgress: (s) => console.log('Crawling:', s.currentUrl) });
   console.log('\\n=== Results ===');
   console.log('Pages crawled:', result.crawlResult.pagesProcessed);
   console.log('Token summary:', JSON.stringify(result.tokenSummary, null, 2));
   console.log('Evidence entries:', result.evidenceCount);
   "
   ```

2. Inspect the output:
   - Open .uidna/tokens/all-colors.json -- verify colors look reasonable (hex values, not browser defaults)
   - Open .uidna/tokens/all-typography.json -- verify font families and sizes look correct
   - Open .uidna/evidence/evidence-index.json -- verify evidence entries have pageUrl, selector, computedStyles
   - Check .uidna/evidence/screenshots/ -- verify screenshot crops exist

3. Run the same crawl again and check for diff:
   - Should see "unchanged" pages in diff report

4. Verify robots.txt compliance:
   - Try a site with restrictive robots.txt and confirm pages are skipped
  </verify>
  <done>User confirms: extracted tokens match visual reality of crawled site, evidence has full provenance, re-crawl diff works, robots.txt compliance verified</done>
</task>

</tasks>

<verification>
1. `npx vitest run` passes all tests
2. Pipeline produces meaningful token output for a real website
3. Evidence entries have all NORM-03 required fields
4. Re-crawl diff detection works
5. Human confirms output quality is reasonable
</verification>

<success_criteria>
All Phase 1 success criteria verified:
1. User can crawl 20-100 pages from seed URL respecting robots.txt and rate limits
2. Crawler handles dynamic content (CSS-in-JS, framework-specific rendering) without missing styles
3. Extracted tokens (colors, typography, spacing, radii, shadows, z-index, motion, icons, imagery) match computed styles
4. Every extracted observation links to evidence (page URL, DOM selector, timestamp, screenshot crop)
5. User can re-crawl a site and see diff of what changed since last crawl
</success_criteria>

<output>
After completion, create `.planning/phases/01-foundation-crawling-infrastructure/01-07-SUMMARY.md`
</output>
