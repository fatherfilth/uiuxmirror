---
phase: 01-foundation-crawling-infrastructure
plan: 07
type: execute
wave: 6
depends_on: ["01-06"]
files_modified:
  - tests/integration/pipeline.test.ts
  - tests/unit/extractors.test.ts
  - tests/fixtures/sample-page.html
  - vitest.config.ts
autonomous: false

must_haves:
  truths:
    - "End-to-end pipeline crawls a real site and produces tokens with evidence"
    - "All 8 token extractors produce valid typed output"
    - "Re-crawl diff detection works correctly"
    - "User visually confirms output quality against a known site"
  artifacts:
    - path: "tests/integration/pipeline.test.ts"
      provides: "Integration test for full pipeline"
      min_lines: 50
    - path: "tests/unit/extractors.test.ts"
      provides: "Unit tests for individual extractors"
      min_lines: 80
  key_links:
    - from: "tests/integration/pipeline.test.ts"
      to: "src/orchestrator.ts"
      via: "calls runPipeline with test config"
      pattern: "runPipeline"
---

<objective>
Write integration and unit tests for the complete Phase 1 pipeline, then verify end-to-end against a real website with human inspection.

Purpose: Confirm all Phase 1 requirements work together. The pipeline should extract meaningful tokens from a real site. Tests catch regressions. Human verification ensures the output quality matches expectations.

Output: Test suite that validates the pipeline, plus human-verified confirmation that the crawler and extractors produce useful design token output.
</objective>

<execution_context>
@C:/Users/Karl/.claude/get-shit-done/workflows/execute-plan.md
@C:/Users/Karl/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@C:/Users/Karl/UIUX-Mirror/.planning/PROJECT.md
@C:/Users/Karl/UIUX-Mirror/.planning/ROADMAP.md
@C:/Users/Karl/UIUX-Mirror/.planning/phases/01-foundation-crawling-infrastructure/01-06-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Write unit tests for extractors and integration tests for pipeline</name>
  <files>tests/unit/extractors.test.ts, tests/integration/pipeline.test.ts, tests/fixtures/sample-page.html, vitest.config.ts</files>
  <action>
Set up vitest configuration and write tests.

1. vitest.config.ts at project root:
```typescript
import { defineConfig } from 'vitest/config';
export default defineConfig({
  test: {
    include: ['tests/**/*.test.ts'],
    testTimeout: 60000,  // 60s for integration tests with Playwright
  },
});
```

2. tests/fixtures/sample-page.html:
   Create a static HTML file with known design tokens for predictable extraction:
   - A few elements with specific colors (#3b82f6, #ef4444, #10b981)
   - Typography: Inter font family, sizes 14px, 16px, 24px, 32px
   - Spacing: 8px, 16px, 24px padding values
   - CSS custom properties: --primary-color, --text-color, --spacing-md
   - Border radius: 4px, 8px
   - Box shadow on a card element
   - A simple transition: 0.2s ease on buttons
   - An inline SVG icon
   - An img element with aspect ratio

3. tests/unit/extractors.test.ts:
   Test extractors against the fixture page using Playwright directly (not the crawler).

   ```typescript
   import { chromium, Browser, Page } from 'playwright';
   import { describe, it, expect, beforeAll, afterAll } from 'vitest';
   import path from 'path';

   let browser: Browser;
   let page: Page;

   beforeAll(async () => {
     browser = await chromium.launch();
     const context = await browser.newContext();
     page = await context.newPage();
     const fixturePath = path.resolve('tests/fixtures/sample-page.html');
     await page.goto(`file://${fixturePath}`);
   });

   afterAll(async () => { await browser.close(); });
   ```

   Tests:
   a. extractColors returns ColorToken[] with known colors from fixture
   b. extractTypography returns font sizes matching fixture (14, 16, 24, 32px)
   c. extractSpacing returns known spacing values
   d. extractCustomProperties returns --primary-color etc.
   e. extractRadii returns known radii
   f. extractShadows returns shadow from card element
   g. extractMotionTokens returns transition duration from button
   h. extractIconTokens detects inline SVG
   i. extractImageryTokens detects img aspect ratio
   j. All tokens have evidence with selector and computedStyles

4. tests/integration/pipeline.test.ts:
   Integration test using the full pipeline against example.com.

   ```typescript
   import { describe, it, expect } from 'vitest';
   import { runPipeline } from '../../src/index.js';
   import { loadConfig } from '../../src/shared/index.js';
   import fs from 'fs-extra';

   describe('Pipeline Integration', () => {
     const outputDir = '.uidna-test';

     afterAll(async () => { await fs.remove(outputDir); });

     it('crawls example.com and extracts tokens', async () => {
       const config = loadConfig({
         seedUrls: ['https://example.com'],
         maxPages: 1,
         maxDepth: 0,
         outputDir,
       });

       const result = await runPipeline({ config });

       expect(result.crawlResult.pagesProcessed).toBe(1);
       expect(result.crawlResult.pagesFailed).toBe(0);
       expect(result.evidenceCount).toBeGreaterThan(0);
       expect(result.outputDir).toBe(outputDir);

       // Verify files on disk
       expect(await fs.pathExists(path.join(outputDir, 'tokens'))).toBe(true);
       expect(await fs.pathExists(path.join(outputDir, 'evidence'))).toBe(true);
       expect(await fs.pathExists(path.join(outputDir, 'snapshots'))).toBe(true);
     });

     it('second crawl produces diff report', async () => {
       const config = loadConfig({
         seedUrls: ['https://example.com'],
         maxPages: 1,
         maxDepth: 0,
         outputDir,
       });

       const result = await runPipeline({ config });

       expect(result.diffResult).toBeDefined();
       expect(result.diffResult!.unchanged.length).toBeGreaterThanOrEqual(0);
     });
   });
   ```

Run tests with: `npx vitest run`
  </action>
  <verify>
Run `npx vitest run` -- all tests should pass.
Specifically:
- Unit tests confirm extractors produce typed tokens from fixture HTML
- Integration test confirms pipeline produces output files from example.com
- Second pipeline run confirms diff detection works
  </verify>
  <done>Unit tests validate all 8 extractors against fixture HTML with known values. Integration tests validate end-to-end pipeline against example.com. Diff detection confirmed by sequential crawl test.</done>
</task>

<task type="checkpoint:human-verify" gate="blocking">
  <name>Task 2: Human verification of pipeline output quality</name>
  <what-built>Complete Phase 1 pipeline: crawler with robots.txt compliance, stealth, framework detection, all 8 token extractors, evidence storage, diff tracking, and CLI entry point. Automated tests pass confirming correctness.</what-built>
  <how-to-verify>
1. Run the pipeline against a real website (suggest https://tailwindcss.com or another site you are familiar with):
   ```
   cd C:/Users/Karl/UIUX-Mirror
   npx tsx src/cli.ts https://tailwindcss.com --max-pages 5 --max-depth 1
   ```

2. Inspect the output:
   - Open .uidna/tokens/all-colors.json -- verify colors look reasonable (hex values, not browser defaults)
   - Open .uidna/tokens/all-typography.json -- verify font families and sizes look correct
   - Open .uidna/evidence/evidence-index.json -- verify evidence entries have pageUrl, selector, computedStyles
   - Check .uidna/evidence/screenshots/ -- verify screenshot crops exist

3. Run the same crawl again and check for diff:
   ```
   npx tsx src/cli.ts https://tailwindcss.com --max-pages 5 --max-depth 1
   ```
   - Should see "unchanged" pages in diff report

4. Verify robots.txt compliance:
   - Try a site with restrictive robots.txt and confirm pages are skipped
  </how-to-verify>
  <resume-signal>Type "approved" if token quality, evidence, and diff are satisfactory. If issues found, describe them and they will be documented in .planning/issues/ for tracking. Specific failure criteria: if extracted colors are ALL browser defaults (black text on transparent), if evidence entries are missing selectors or computedStyles, or if the diff report shows incorrect changes on an unchanged site -- describe the issue and it will be logged as a blocker for Phase 2.</resume-signal>
  <done>User confirms: extracted tokens match visual reality of crawled site (colors are not all browser defaults, typography matches visible fonts), evidence has full provenance (pageUrl + selector + computedStyles populated), re-crawl diff works (unchanged site shows unchanged), robots.txt compliance verified (blocked pages are skipped). If token quality issues are found, they are documented in .planning/issues/ with specific symptoms for targeted fixing before Phase 2.</done>
</task>

</tasks>

<verification>
1. `npx vitest run` passes all tests
2. Pipeline produces meaningful token output for a real website
3. Evidence entries have all NORM-03 required fields
4. Re-crawl diff detection works
5. Human confirms output quality is reasonable
</verification>

<success_criteria>
All Phase 1 success criteria verified:
1. User can crawl 20-100 pages from seed URL respecting robots.txt and rate limits
2. Crawler handles dynamic content (CSS-in-JS, framework-specific rendering) without missing styles
3. Extracted tokens (colors, typography, spacing, radii, shadows, z-index, motion, icons, imagery) match computed styles
4. Every extracted observation links to evidence (page URL, DOM selector, timestamp, screenshot crop)
5. User can re-crawl a site and see diff of what changed since last crawl
6. User can run the tool from CLI (`npx tsx src/cli.ts <url>`)
</success_criteria>

<output>
After completion, create `.planning/phases/01-foundation-crawling-infrastructure/01-07-SUMMARY.md`
</output>
