---
phase: 02-normalization-component-mining
plan: 02
type: tdd
wave: 1
depends_on: []
files_modified:
  - src/normalization/cross-page-validator.ts
  - src/normalization/spacing-scale-detector.ts
  - src/scoring/token-scorer.ts
  - src/scoring/index.ts
  - tests/normalization/cross-page-validator.test.ts
  - tests/scoring/token-scorer.test.ts
autonomous: true

must_haves:
  truths:
    - "Only tokens appearing on 3+ pages are promoted to design standards"
    - "Tokens on fewer than 3 pages are retained but marked low confidence"
    - "Confidence scores range 0-1 based on page frequency and occurrence density"
    - "Spacing values are analyzed for base unit (GCD-based scale detection)"
  artifacts:
    - path: "src/normalization/cross-page-validator.ts"
      provides: "Cross-page frequency validation with configurable threshold"
      exports: ["validateCrossPage", "CrossPageResult"]
    - path: "src/normalization/spacing-scale-detector.ts"
      provides: "GCD-based spacing scale detection"
      exports: ["detectSpacingScale", "SpacingScale"]
    - path: "src/scoring/token-scorer.ts"
      provides: "Confidence scoring for tokens"
      exports: ["calculateTokenConfidence", "ConfidenceScore"]
  key_links:
    - from: "src/normalization/cross-page-validator.ts"
      to: "src/types/evidence.ts"
      via: "TokenEvidence.pageUrl for page counting"
      pattern: "evidence.*pageUrl"
    - from: "src/scoring/token-scorer.ts"
      to: "src/normalization/cross-page-validator.ts"
      via: "Page count feeds into confidence calculation"
      pattern: "pageCount.*totalPages"
---

<objective>
Implement cross-page validation (3+ page threshold) and confidence scoring for tokens, plus GCD-based spacing scale detection. TDD ensures the statistical thresholds and scoring formulas work correctly.

Purpose: NORM-04 requires cross-page validation to filter noise. NORM-05 requires confidence scores. Spacing scale detection supports spacing normalization.
Output: Cross-page validator, spacing scale detector, token scorer, with passing tests.
</objective>

<execution_context>
@C:/Users/Karl/.claude/get-shit-done/workflows/execute-plan.md
@C:/Users/Karl/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-normalization-component-mining/02-RESEARCH.md
@src/types/tokens.ts
@src/types/evidence.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Write failing tests for cross-page validation, spacing scale detection, and confidence scoring</name>
  <files>
    tests/normalization/cross-page-validator.test.ts
    tests/scoring/token-scorer.test.ts
  </files>
  <action>
    1. Create `tests/normalization/cross-page-validator.test.ts` with tests:
      - Token appearing on 5 pages (threshold 3) is validated as standard
      - Token appearing on 2 pages (threshold 3) is filtered out
      - Token appearing on exactly 3 pages passes threshold
      - Empty token list returns empty result
      - Results sorted by confidence (most frequent first)
      - All tokens below threshold still returned with low confidence flag
      - Use mock tokens with evidence arrays containing different pageUrl values

    2. Create `tests/scoring/token-scorer.test.ts` with tests:
      - Token on 10/20 pages = confidence ~0.5 (plus density bonus)
      - Token on 1/20 pages = low confidence
      - Token on 20/20 pages = high confidence (capped at 1.0)
      - Confidence level: < 3 pages = 'low', 0.3-0.6 = 'medium', > 0.6 = 'high'
      - Density bonus: token appearing 50 times on 5 pages gets density boost
      - Reasoning string includes page count and occurrence count

    3. Add spacing scale tests to cross-page-validator test file (or separate file):
      - Values [4, 8, 12, 16, 24, 32] detect baseUnit 4 with full coverage
      - Values [8, 16, 24, 32, 48, 64] detect baseUnit 8
      - Values [7, 13, 23, 41] detect baseUnit 1 (no clear scale)
      - Empty array returns baseUnit 1, empty scale
      - Coverage calculation is correct (% of values that are exact multiples)

    4. Run tests: `npx vitest run tests/normalization/cross-page-validator tests/scoring/` -- all must FAIL (RED).
  </action>
  <verify>`npx vitest run tests/normalization/cross-page-validator tests/scoring/` shows all tests failing (RED)</verify>
  <done>Test files written with meaningful RED failures for cross-page validation, spacing scale detection, and confidence scoring</done>
</task>

<task type="auto">
  <name>Task 2: Implement cross-page validator, spacing scale detector, and token scorer (GREEN)</name>
  <files>
    src/normalization/cross-page-validator.ts
    src/normalization/spacing-scale-detector.ts
    src/scoring/token-scorer.ts
    src/scoring/index.ts
    src/normalization/index.ts
  </files>
  <action>
    1. Create `src/normalization/cross-page-validator.ts`:
      - `interface CrossPageResult<T>`: { token: T, pageUrls: Set<string>, occurrenceCount: number, confidence: number, isStandard: boolean }
      - `validateCrossPage<T extends { evidence: TokenEvidence[] }>(tokens: T[], minPageCount: number = 3, totalPages: number): CrossPageResult<T>[]`
        - For each token, extract unique pageUrls from evidence
        - Count occurrences (total evidence entries)
        - Calculate raw confidence = pageUrls.size / totalPages
        - Set isStandard = pageUrls.size >= minPageCount
        - Sort by confidence descending
        - Return ALL tokens (standards and non-standards) with isStandard flag

    2. Create `src/normalization/spacing-scale-detector.ts`:
      - `function gcd(a: number, b: number): number` -- Euclidean algorithm
      - `interface SpacingScale`: { baseUnit: number, scale: number[], coverage: number }
      - `detectSpacingScale(spacingValues: number[]): SpacingScale`
        - Round to integers, filter positive
        - Calculate GCD of all values using reduce
        - Generate scale (unique multiples of baseUnit, sorted)
        - Calculate coverage (% of values that are exact multiples of baseUnit)
        - If GCD is 1 and values > 3, try common bases [4, 8, 6, 10] and pick best coverage (same heuristic as Phase 1 detectBaseUnit but more comprehensive)

    3. Create `src/scoring/token-scorer.ts`:
      - `interface ConfidenceScore`: { value: number, level: 'low' | 'medium' | 'high', reasoning: string }
      - `calculateTokenConfidence(token: { evidence: TokenEvidence[] }, totalPagesCrawled: number, minPageThreshold: number = 3): ConfidenceScore`
        - Extract unique pages from evidence
        - Raw confidence = pageCount / totalPagesCrawled
        - Density bonus = min(avgOccurrencesPerPage / 5, 0.2) -- cap at +0.2
        - Final value = min(rawConfidence + densityBonus, 1.0)
        - Level: pageCount < minPageThreshold = 'low', value < 0.3 = 'low', value < 0.6 = 'medium', else 'high'
        - Reasoning: "Appears on {pageCount}/{total} pages ({pct}%) with {occurrences} total occurrences"

    4. Create `src/scoring/index.ts` barrel export.

    5. Update `src/normalization/index.ts` to export cross-page-validator and spacing-scale-detector.

    6. Run tests: `npx vitest run tests/normalization/cross-page-validator tests/scoring/` -- all must PASS (GREEN).
  </action>
  <verify>`npx vitest run tests/normalization/cross-page-validator tests/scoring/` passes all tests (GREEN)</verify>
  <done>Cross-page validator filters tokens by 3+ page threshold, spacing scale detector finds base unit via GCD, confidence scorer produces 0-1 scores with levels, all tests pass</done>
</task>

</tasks>

<verification>
- `npx tsc --noEmit` passes with zero errors
- `npx vitest run tests/normalization/ tests/scoring/` passes all tests
- Cross-page validation correctly filters by page threshold
- Confidence scores are reasonable (0-1 range, correct levels)
- Spacing scale detection finds correct base units
</verification>

<success_criteria>
- 3+ page threshold enforced before declaring token as standard
- Confidence scores incorporate page frequency and occurrence density
- GCD-based spacing scale correctly identifies base unit and coverage
- All scoring/validation code has passing tests
</success_criteria>

<output>
After completion, create `.planning/phases/02-normalization-component-mining/02-02-SUMMARY.md`
</output>
